{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from wavenet_model import *\n",
    "from audio_data import WavenetDataset\n",
    "from wavenet_training import *\n",
    "from model_logging import * # Or TensorboardLogger if using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor # Default data type\n",
    "ltype = torch.LongTensor # Default label type\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    print('Using GPU')\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    ltype = torch.cuda.LongTensor\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WaveNetModel(layers=10,\n",
    "                     blocks=3,\n",
    "                     dilation_channels=32,\n",
    "                     residual_channels=32,\n",
    "                     skip_channels=1024,\n",
    "                     end_channels=512,\n",
    "                     output_length=16, # Adjust based on dataset/task\n",
    "                     dtype=dtype,\n",
    "                     bias=True)\n",
    "\n",
    "# If using GPU, move the model to GPU\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "print('Model initialized:')\n",
    "print('Receptive field:', model.receptive_field)\n",
    "print('Parameter count:', model.parameter_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure dataset_file path and file_location are correct\n",
    "# item_length should generally be model.receptive_field + model.output_length - 1\n",
    "data = WavenetDataset(dataset_file='train_samples/bach_chaconne/dataset.npz',\n",
    "                      item_length=model.receptive_field + model.output_length - 1,\n",
    "                      target_length=model.output_length,\n",
    "                      file_location='train_samples/bach_chaconne',\n",
    "                      test_stride=500) # test_stride splits data for testing\n",
    "print('Dataset loaded with ' + str(len(data)) + ' items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example using the standard logger (modify if using TensorBoard)\n",
    "logger = Logger(log_interval=200, validation_interval=400) # Adjust intervals as needed\n",
    "\n",
    "trainer = WavenetTrainer(model=model,\n",
    "                         dataset=data,\n",
    "                         lr=0.001, # Learning rate\n",
    "                         snapshot_path='snapshots', # Directory to save model checkpoints\n",
    "                         snapshot_name='chaconne_model', # Base name for checkpoints\n",
    "                         snapshot_interval=1000, # How often to save checkpoints\n",
    "                         logger=logger,\n",
    "                         dtype=dtype,\n",
    "                         ltype=ltype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting training...')\n",
    "trainer.train(batch_size=16, # Adjust batch size based on GPU memory\n",
    "              epochs=2)      # Train for 2 epochs as requested\n",
    "print('Training finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Load the best/latest model from snapshots if not continuing directly\n",
    "# model = load_latest_model_from('snapshots', use_cuda=use_cuda) # Ensure model is on the correct device (CPU/GPU)\n",
    "\n",
    "# Prepare starting data if needed (example uses data from the dataset)\n",
    "# start_data = data[some_index][0]\n",
    "# start_data = torch.max(start_data, 0)[1] # Convert one-hot to integers if necessary\n",
    "# if use_cuda:\n",
    "#     start_data = start_data.cuda()\n",
    "\n",
    "# Generate audio\n",
    "num_samples_to_generate = 16000 # Example: 1 second at 16kHz\n",
    "print(f'Generating {num_samples_to_generate} samples...')\n",
    "\n",
    "generated_audio = model.generate_fast(num_samples=num_samples_to_generate,\n",
    "                                      # first_samples=start_data, # Optional starting sequence\n",
    "                                      temperature=1.0) # Temperature for sampling diversity\n",
    "print('Sample generation complete.')\n",
    "\n",
    "# You can then save or play the generated audio\n",
    "# import soundfile as sf\n",
    "# sf.write('generated_sample.wav', generated_audio.cpu().numpy(), 16000) # Example using soundfile\n",
    "\n",
    "# Or use IPython display within the notebook\n",
    "import IPython.display as ipd\n",
    "ipd.Audio(generated_audio.cpu().numpy(), rate=16000) # Ensure audio is on CPU for numpy conversion"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
